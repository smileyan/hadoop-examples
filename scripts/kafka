1. Topic
2. Partitions
3. Producers and consumers
4. Brokers

Step 2: Start the server

> bin/zookeeper-server-start.sh config/zookeeper.properties
> bin/kafka-server-start.sh config/server.properties

Step 3: Create a topic

> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test

Step 4: Send some messages

> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

Step 5: Start a consumer

> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning

Step 7: Use Kafka Connect to import/export data

> echo -e "foo\nbar" > test.txt

> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties

> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic connect-test --from-beginning

Step 8: Use Kafka Streams to process data

> echo -e "all streams lead to kafka\nhello kafka streams\njoin kafka summit" > file-input.txt

> bin/kafka-topics.sh --create \
        --zookeeper localhost:2181 \
        --replication-factor 1 \
        --partitions 1 \
        --topic streams-file-input

> cat file-input.txt | bin/kafka-console-producer.sh --broker-list localhost:9092 --topic streams-file-input

> bin/kafka-run-class.sh org.apache.kafka.streams.examples.wordcount.WordCountDemo

> bin/kafka-console-consumer.sh --zookeeper localhost:2181 \
        --topic streams-wordcount-output \
        --from-beginning \
        --formatter kafka.tools.DefaultMessageFormatter \
        --property print.key=true \
        --property print.value=true \
        --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \
        --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer



