wget http://en.wikipedia.org/wiki/Hortonworks

>>> lines = sc.textFile('/home/hua/tmp/my-app/scripts/spark/Hortonworks')
>>> linesFiltered = lines.filter( lambda x: len(x) > 0)
>>> count = linesFiltered.count()
>>> print count

spark-submit --class org.apache.spark.examples.SparkPi 
             --master yarn-client 
             --num-executors 3 
             --driver-memory 512m 
             --executor-memory 512m -
             -executor-cores 1 
             lib/spark-examples*.jar 10

spark-shell --master yarn-client 
            --driver-memory 512m 
            --executor-memory 512m

val file = sc.textFile("/tmp/data")
val counts = file.flatMap(line => line.split(" "))
                 .map(word => (word, 1))
                 .reduceByKey(_ + _)

counts.saveAsTextFile("/tmp/wordcount")
counts.count()
counts.toArray().foreach(println)

spark-shell --num-executors 2 
            --executor-memory 512m 
            --master yarn-client

import org.apache.spark.sql.SparkSession

val spark = SparkSession
  .builder()
  .appName("Spark SQL Example")
  .config("spark.some.config.option", "some-value")
  .getOrCreate()

// For implicit conversions like converting RDDs to DataFrames
import spark.implicits._

val df = spark.read.json("examples/src/main/resources/people.json")

// Displays the content of the DataFrame to stdout
df.show()

df.printSchema()

df.select("name").show()
df.select($"name", $"age" + 1).show()
df.filter($"age" > 21).show
df.groupBy($"age").count().show()
